{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QTM 151 - Introduction to Statistical Computing II\n",
    "## Lecture 08 - Data Wrangling with Pandas\n",
    "**Author:** Danilo Freire (danilo.freire@emory.edu, Emory University)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello again! 🥳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap of last class 📚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In our last class, we learned\n",
    "\n",
    "- How to write functions with `def` and `return`\n",
    "- What **parameters, arguments, and return values** are\n",
    "- How to combine functions with `if` statements\n",
    "- How to use [lambda](https://realpython.com/python-lambda/) to create quick, throwaway functions\n",
    "\n",
    "![](figures/functions.webp)\n",
    "![](figures/lambda.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's plan 📅\n",
    "\n",
    "- Introduction to `pandas`, the main library for data manipulation in Python\n",
    "- Learn how to apply functions to many variables at once\n",
    "- How to use the `apply` and `map` functions\n",
    "- Learn how to recode and replace variables in a dataset\n",
    "- Specifically focus on replacing `NaN` values (\"Not a Number\" - missing data)\n",
    "- Cover how to convert variables from one type to another\n",
    "- Learn how to create new variables based on existing ones\n",
    "- Finally, we will learn about `.py` files and how to import them as modules\n",
    "\n",
    "![](figures/pandas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations over many variables using Pandas 🐼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas 🐼\n",
    "\n",
    "- `pandas` is the main library for **data manipulation** in Python 🐼\n",
    "- We will use it a lot in this course (and in your life as a data scientist!)\n",
    "- It is built on top of `numpy` and `matplotlib`, and has [a gazillion functions to work with data](https://pandas.pydata.org/docs/reference/index.html) 😁\n",
    "- If you use `R` already, think about it as the `dplyr` of Python\n",
    "  - A list of [equivalences between `dplyr` and `pandas`](https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_r.html)\n",
    "- We will learn more about it in the next classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying functions to a dataset\n",
    "\n",
    "- The `apply` function is used to **apply a function to a dataset**\n",
    "  - (This course is full of surprises, isn't it? 😄)\n",
    "- It is a **method of a pandas DataFrame**\n",
    "- It can be used with built-in functions, custom functions, or lambda functions\n",
    "  - `df.apply(function)`\n",
    "- You can apply functions to rows or columns\n",
    "  - `df.apply(function, axis=0)` applies the function to each column (default)\n",
    "  - `df.apply(function, axis=1)` applies the function to each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying functions to a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "})\n",
    "\n",
    "print(df.apply(np.sqrt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.apply(np.sum, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.apply(lambda x: x**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying functions to a dataset\n",
    "\n",
    "- Let's do a quick exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Add variables\n",
    "data[\"age\"] = [18,29,15,32,6]\n",
    "data[\"num_underage_siblings\"] = [0,0,1,1,0]\n",
    "data[\"num_adult_siblings\"] = [1,0,0,1,0]\n",
    "\n",
    "from IPython.display import display # To match Quarto's display output\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying functions to a dataset\n",
    "\n",
    "- Now let's define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first two functions return True/False depending on age constraints\n",
    "# The third function returns the sum of two numbers\n",
    "# The fourth function returns a string with the age bracket\n",
    "\n",
    "fn_iseligible_vote = lambda age: age >= 18\n",
    "\n",
    "fn_istwenties = lambda age: (age >= 20) & (age < 30)\n",
    "\n",
    "fn_sum = lambda x,y: x + y\n",
    "\n",
    "def fn_agebracket(age):\n",
    "    if (age >= 18):\n",
    "        status = \"Adult\"\n",
    "    elif (age >= 10) & (age < 18):\n",
    "        status = \"Adolescent\"\n",
    "    else:\n",
    "        status = \"Child\"\n",
    "    return(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying functions to a dataset\n",
    "\n",
    "- Now let's apply the functions to the `data[\"age\"]` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"can_vote\"]    = data[\"age\"].apply(fn_iseligible_vote)\n",
    "data[\"in_twenties\"] = data[\"age\"].apply(fn_istwenties)\n",
    "data[\"age_bracket\"] = data[\"age\"].apply(fn_agebracket)\n",
    "\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new variable\n",
    "\n",
    "- You can also create a new variable using the `apply` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new variable\n",
    "data[\"new_var\"] = data[\"age\"].apply(lambda age: age >= 18)\n",
    "\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting a variable\n",
    "\n",
    "- You can also delete a variable using the `drop` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = [\"new_var\"])\n",
    "\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping functions to a list, array, or series\n",
    "\n",
    "- The `map` function is used to **apply a function to a list, an array, or a series**\n",
    "  - A series is a single column of a pandas DataFrame\n",
    "- **In pandas**, `map` works very similarly to the `apply` function, and they are interchangeable when working with series\n",
    "- `map` can be faster than `apply` for simple functions, but `apply` is more flexible as it can be used with DataFrames (many columns)\n",
    "- However, if you are using regular lists (e.g., `list01 = [1,2,3]`), you should use `map` instead of `apply`\n",
    "  - `apply` is not a built-in Python function for lists in the same way `map` is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"age_bracket01\"] = data[\"age\"].map(fn_agebracket)\n",
    "\n",
    "display(data[[\"age\",\"age_bracket01\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"age_bracket02\"] = data[\"age\"].apply(fn_agebracket)\n",
    "\n",
    "display(data[[\"age\",\"age_bracket02\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping functions to a list, array, or series\n",
    "\n",
    "- Using `map` with a list and an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list\n",
    "list01 = [1,2,3,4,5]\n",
    "\n",
    "# Map a function to the list\n",
    "list02 = list(map(lambda x: x**2, list01))\n",
    "\n",
    "print(list02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array\n",
    "array01 = np.array([1,2,3,4,5])\n",
    "\n",
    "# Map a function to the array\n",
    "array02 = np.array(list(map(lambda x: x**2, array01)))\n",
    "\n",
    "print(array02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trying to use `apply` with a list or an array will raise an error\n",
    "```python\n",
    "# Create a list\n",
    "list01 = [1,2,3,4,5]\n",
    "\n",
    "# Apply a function to the list\n",
    "# list02 = list(apply(lambda x: x**2, list01)) # This would cause NameError\n",
    "\n",
    "# print(list02)\n",
    "```\n",
    "```verbatim\n",
    "---------------------------------------------------------------------------\n",
    "NameError                                 Traceback (most recent call last)\n",
    "Cell In[168], line 5\n",
    "      2 list01 = [1,2,3,4,5]\n",
    "      4 # Apply a function to the list\n",
    "----> 5 list02 = list(apply(lambda x: x**2, list01))\n",
    "      7 print(list02)\n",
    "\n",
    "NameError: name 'apply' is not defined\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it yourself! 🚀 {#sec:exercise-02}\n",
    "\n",
    "- Write a lambda function checking whether `num_siblings` $\\ge 1$\n",
    "- Add a variable to the dataset called `has_siblings`\n",
    "- Assign True/False to this variable using `apply()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# fn_has_siblings = lambda ... : ...\n",
    "\n",
    "# data[\"has_siblings\"] = data[...].apply(...)\n",
    "\n",
    "# display(data[[\"num_adult_siblings\",\"has_siblings\"]]) # Assuming you use num_adult_siblings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules 📦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules\n",
    "### What is a module?\n",
    "\n",
    "- While `.ipynb` files are great for learning and teaching, they are not the best for sharing code\n",
    "- When you write a lot of functions, you should save them in a `.py` file, which is a **Python script**\n",
    "- A Python script, or module, is just a file containing Python code\n",
    "- This code can be functions, classes, or variables\n",
    "- A folder containing Python scripts is called a **package**\n",
    "- You can import modules to use their code in your own code\n",
    "\n",
    "- We can import functions into the working environment from a file \n",
    "\n",
    "```python\n",
    "# import scripts.example_functions as ef\n",
    "\n",
    "# print(ef.fn_quadratic(2))\n",
    "# print(ef.fn_cubic(3))\n",
    "\n",
    "# ef.message_hello(\"Juan\")\n",
    "```\n",
    "*(This code assumes you have a folder named `scripts` with a file `example_functions.py` in it, containing the respective functions. For this notebook, we won't run this cell as the file structure isn't set up here.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules\n",
    "### Importing variables\n",
    "\n",
    "- You can also import variables from a module\n",
    "- However, it is not recommended to import variables\n",
    "- It is better to import functions and use them to create variables\n",
    "- This is because variables can be changed in the module, leading to unexpected results\n",
    "\n",
    "- Example:\n",
    "\n",
    "```python\n",
    "# import scripts.example_variables as ev\n",
    "\n",
    "# # When we run this code\n",
    "# # the value of alpha will be overwritten\n",
    "\n",
    "# alpha = 1\n",
    "# print(alpha)\n",
    "# print(ev.alpha)\n",
    "\n",
    "# from scripts.example_variables import *\n",
    "\n",
    "# print(alpha)\n",
    "# print(beta)\n",
    "# print(gamma)\n",
    "# print(delta)\n",
    "```\n",
    "*(This code assumes a `scripts/example_variables.py` file. We won't run this.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading packages and dataset 📦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our dataset: Formula 1 World Championships 🏁🏎️\n",
    "\n",
    "- First, we will load the packages we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then, we will load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the file 'data_raw/circuits.csv' is in the correct path relative to the notebook\n",
    "# Or use the direct URL\n",
    "try:\n",
    "    circuits = pd.read_csv(\"data_raw/circuits.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Local file 'data_raw/circuits.csv' not found. Attempting to download from internet...\")\n",
    "    circuits_url = \"https://raw.githubusercontent.com/danilofreire/qtm151-summer/main/lectures/lecture-08/data_raw/circuits.csv\"\n",
    "    try:\n",
    "        circuits = pd.read_csv(circuits_url)\n",
    "        print(\"Successfully downloaded circuits.csv from GitHub.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not download from URL. Error: {e}\")\n",
    "        circuits = pd.DataFrame() # Create an empty DataFrame if loading fails\n",
    "\n",
    "from IPython.display import display\n",
    "if not circuits.empty:\n",
    "    display(circuits.head(2))\n",
    "else:\n",
    "    print(\"Failed to load the circuits dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our dataset: Formula 1 World Championships 🏁🏎️\n",
    "\n",
    "- The dataset contains information about F1 circuits, such as its name, location, latitude, longitude, and more\n",
    "- You can find more information about the dataset [here](https://www.kaggle.com/datasets/rohanrao/formula-1-world-championship-1950-2020/data)\n",
    "- The dataset is available in the course's GitHub repository [here](https://github.com/danilofreire/qtm151-summer/blob/main/lectures/lecture-08/data_raw/circuits.csv)\n",
    "  - Or you can download it using the command above\n",
    "- Let's see how the codebook looks like\n",
    "- More information about [Formula 1 here](https://en.wikipedia.org/wiki/Formula_One)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codebook 📚\n",
    "\n",
    "![](figures/codebook.png)\n",
    "\n",
    "- `Field` - Name of the variable\n",
    "- `Type` - Type of the variable\n",
    "  - Integer (`int`), string (`str` - `varchar`), and float (`float`)\n",
    "- `Description` - Label with a description of the variable\n",
    "- **Quick discussion**: What does `varchar(255)` mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has {circuits.shape[1] if 'circuits' in locals() and not circuits.empty else 'N/A'} columns (variables) and {circuits.shape[0] if 'circuits' in locals() and not circuits.empty else 'N/A'} rows (observations).\n",
    "\n",
    "The columns are:\n",
    "  - `circuitId`: Unique identifier for the circuit\n",
    "  - `circuitRef`: Unique reference for the circuit\n",
    "  - `name`: Name of the circuit\n",
    "  - `location`: Location \n",
    "  - `country`: Country where the circuit is located\n",
    "  - `lat`: Latitude \n",
    "  - `lng`: Longitude\n",
    "  - `alt`: Altitude\n",
    "  - `url`: URL of the circuit's Wikipedia page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaN values 🚫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a `NaN` value?\n",
    "\n",
    "- `NaN` stands for \"Not a Number\"\n",
    "- It is a special value in Python that represents missing data\n",
    "- `NaN` values can be found in datasets for various reasons\n",
    "  - Data entry errors\n",
    "  - Data cleaning and processing errors\n",
    "  - Data collection errors\n",
    "  - Data transformation errors\n",
    "- We (often) need to handle `NaN` values before we can analyse the data\n",
    "\n",
    "- `NaN` values can be found in different types of variables\n",
    "  - Numeric variables\n",
    "  - Categorical variables\n",
    "  - Date variables\n",
    "  - Text variables\n",
    "- We will focus on numeric variables today\n",
    "- `pandas` and `numpy` have functions to handle `NaN` values\n",
    "  - Note: they handle `NaN` values differently!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations with `NaN` values\n",
    "\n",
    "- `NaN` is a special number, available in `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Ensure numpy is imported\n",
    "np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Often, we cannot perform operations with `NaN` values\n",
    "- Thus, we need to handle them before we can analyse the data\n",
    "\n",
    "- Let's see some examples. We start with `numpy` arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two array with and without \"NaNs\"\n",
    "# The \"np.array()\" functions converts \n",
    "# a list to an array\n",
    "\n",
    "vec_without_nans = np.array([1,1,1])\n",
    "vec_with_nans    = np.array([np.nan,4,5])\n",
    "\n",
    "# When you add the vectors\n",
    "# you will produce a NaN \n",
    "# on any entries with \"NaNs\"\n",
    "print(vec_without_nans * vec_with_nans)\n",
    "print(vec_without_nans / vec_with_nans)\n",
    "print(vec_without_nans + vec_with_nans)\n",
    "print(vec_without_nans - vec_with_nans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics with `NaN` values\n",
    "### Arrays\n",
    "\n",
    "- Some summary statistics functions will not work with `NaN` values\n",
    "- For example, the `mean()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(vec_with_nans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `mean()` function will return `NaN` if there are `NaN` values in the array\n",
    "\n",
    "- To calculate the mean without `NaN` values, we can use the `nanmean()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.nanmean(vec_with_nans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `nanmean()` function will ignore `NaN` values and calculate the mean with the remaining values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics with `NaN` values\n",
    "### Pandas DataFrames\n",
    "\n",
    "- Let's create an empty DataFrame and create a new column `x` with `NaN` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Ensure pandas is imported\n",
    "dataset = pd.DataFrame()\n",
    "dataset[\"x\"] = vec_with_nans # vec_with_nans was defined in a previous cell\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You will see that `pandas` will handle `NaN` values differently: it will **ignore them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"x\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **For R users**: This is the same as `na.rm = TRUE` in R. `pandas` does that by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning 🧹🧽"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "- Data cleaning is the process of preparing data for analysis\n",
    "- It involves identifying and handling missing data, outliers, and other data quality issues\n",
    "- **You guys have no idea** how much time you will spend cleaning data in your life 😅\n",
    "- According to a [Forbes survey](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/), data scientists spend 60% of their time cleaning and preparing data, and 57% say it's the least enjoyable part of their work\n",
    "  - I can **really** relate to that 😂\n",
    "- But remember that **clean data are good data** 🥳\n",
    "\n",
    "- Let's get the data types of the columns in the `circuits` dataset\n",
    "- We use the command `dtypes` for that\n",
    "- `object` means that the variable is a string or a variable with mixed types (e.g., numbers and strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'circuits' in locals() and not circuits.empty:\n",
    "    print(circuits.dtypes)\n",
    "else:\n",
    "    print(\"Circuits DataFrame not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check rows with numeric values\n",
    "\n",
    "- Here we will use the `.str.isnumeric()` function\n",
    "- This function actually combines two functions: `.str` and `.isnumeric()`\n",
    "- The `.str` accessor is used to apply string methods to each element in a Series.\n",
    "- The `.isnumeric()` method then checks if each string consists only of numeric characters.\n",
    "- **Why do we need both?** Because DataFrame columns can sometimes be of `object` type (which can hold strings, numbers, or mixed types). We need to treat the elements as strings first (`.str`) before checking if those strings represent numbers (`.isnumeric()`).\n",
    "- If we used only `.isnumeric()` on a Series that isn't of string type or on a Series with non-string elements, it might not work as expected or could raise an error.\n",
    "\n",
    "- The two dots between the functions are called **method chaining**\n",
    "- It is a way to call multiple methods sequentially on an object\n",
    "- If you use `R`, this is similar to the `%>%` operator in `dplyr`\n",
    "- Let's see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the variable \"alt\" is numeric\n",
    "if 'circuits' in locals() and not circuits.empty and 'alt' in circuits.columns:\n",
    "    # Pandas .str.isnumeric() returns False for NaN, which is desired.\n",
    "    # It also returns False for decimals and negative signs, as it checks for unicode numeric characters.\n",
    "    # For a more robust check if a string can be a float, pd.to_numeric with errors='coerce' is better.\n",
    "    # However, for this specific example from slides, we'll use .str.isnumeric()\n",
    "    print(circuits[\"alt\"].astype(str).str.isnumeric()) # Convert to string first to use .str methods safely\n",
    "else:\n",
    "    print(\"Circuits DataFrame not loaded or 'alt' column missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other examples of chaining methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the variable \n",
    "# \"circuitRef\" is numeric\n",
    "if 'circuits' in locals() and not circuits.empty and 'circuitRef' in circuits.columns:\n",
    "    print(circuits[\"circuitRef\"].astype(str).str.isnumeric())\n",
    "else:\n",
    "    print(\"Circuits DataFrame not loaded or 'circuitRef' column missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the variable \n",
    "# `location` to lowercase\n",
    "if 'circuits' in locals() and not circuits.empty and 'location' in circuits.columns:\n",
    "    print(circuits[\"location\"].str.lower())\n",
    "else:\n",
    "    print(\"Circuits DataFrame not loaded or 'location' column missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract list of non-numeric values\n",
    "\n",
    "- We can use the function `query()` to filter rows in a DataFrame based on a condition expressed as a string.\n",
    "  - `query()` is a method of a pandas DataFrame and it has [many useful functions](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html)!\n",
    "  - We will use it more in the future!\n",
    "- Here we will combine `query()` with `pd.unique()` to extract a list of unique non-numeric-like string values in the 'alt' column.\n",
    "- The `pd.unique()` function will return an array of unique values in a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a list of non-numeric values\n",
    "# The pd.unique() function extracts unique values from a list\n",
    "# Check each value in the alt column to see if it is not numeric\n",
    "# True if it is not numeric, False if it is numeric\n",
    "if 'circuits' in locals() and not circuits.empty and 'alt' in circuits.columns:\n",
    "    # Ensure 'alt' is string type for .str.isnumeric()\n",
    "    # .str.isnumeric() will be False for NaN, empty strings, decimals, negatives.\n",
    "    # We are looking for strings that are *not* purely digits.\n",
    "    condition = circuits['alt'].astype(str).str.isnumeric() == False\n",
    "    subset = circuits[condition]\n",
    "    list_unique = pd.unique(subset[\"alt\"])\n",
    "    print(list_unique)\n",
    "else:\n",
    "    print(\"Circuits DataFrame not loaded or 'alt' column missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace certain values\n",
    "\n",
    "- The `replace` function is used to replace values in a variable\n",
    "- The syntax is `dataframe[\"variable\"].replace(list_old, list_new)`\n",
    "- More information about the function can be found [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'circuits' in locals() and not circuits.empty and 'alt' in circuits.columns:\n",
    "    # \"list_old\" encodes values we want to change\n",
    "    # From the list_unique, we see that the values we want to change are '\\N' and potentially others like '-7' (if it was read as string)\n",
    "    # \"list_new\" encodes the values that will replace the old\n",
    "    list_old = ['\\\\N','-7'] # Note: '\\N' needs to be escaped as '\\\\N' if it's a literal string in the data\n",
    "    list_new = [np.nan, -7] # np.nan for missing, -7 as a number\n",
    "\n",
    "    # This command replaces the values of the \"alt\" column\n",
    "    circuits[\"alt\"] = circuits[\"alt\"].replace(list_old, list_new)\n",
    "    print(\"Values in 'alt' after replacement (first 5 unique values):\")\n",
    "    print(pd.unique(circuits['alt'].dropna())[:5]) # Show some unique non-NaN values\n",
    "else:\n",
    "    print(\"Circuits DataFrame not loaded or 'alt' column missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After the cleaning process is done, you may want to store the dataset again\n",
    "- It's **strongly recommended** to do this in a separate file from the original\n",
    "- Use `to_csv()` to save the dataset as a `.csv` file\n",
    "\n",
    "```python\n",
    "# circuits.to_csv(\"data_clean/circuits_clean.csv\", index=False)\n",
    "```\n",
    "*(Make sure you have a `data_clean` directory or adjust the path)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it yourself! 🧠 {#sec:exercise-04}\n",
    "\n",
    "- Use `.replace()` with the \"country\" column in the `circuits` DataFrame.\n",
    "- Replace \"UK\" with \"United Kingdom\".\n",
    "- Display the unique values of the \"country\" column after replacement to verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# if 'circuits' in locals() and not circuits.empty and 'country' in circuits.columns:\n",
    "    # circuits[\"country\"] = ... .replace(... , ...)\n",
    "    # display(circuits[[\"country\"]].head())\n",
    "    # print(pd.unique(circuits['country']))\n",
    "# else:\n",
    "#     print(\"Circuits DataFrame not loaded or 'country' column missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it yourself! 🧠 {#sec:exercise-05}\n",
    "\n",
    "- What is the column type of \"lat\" or \"lng\" in the `circuits` DataFrame?\n",
    "- Does it have any string variables (values that are strings, not just the column type being 'object' if it contains mixed types)?\n",
    "- Can we use ```.str.isnumeric()``` here directly? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code and explanations here\n",
    "# if 'circuits' in locals() and not circuits.empty:\n",
    "    # print(\"Data type of 'lat':\", circuits['lat'].dtype)\n",
    "    # print(\"Data type of 'lng':\", circuits['lng'].dtype)\n",
    "    \n",
    "    # # To check for string values within a potentially numeric column:\n",
    "    # has_string_in_lat = circuits['lat'].apply(type).eq(str).any()\n",
    "    # print(f\"Does 'lat' column contain any string values? {has_string_in_lat}\")\n",
    "\n",
    "    # # Attempting to use .str.isnumeric() on a float column will typically raise an AttributeError\n",
    "    # try:\n",
    "    #     print(circuits['lat'].str.isnumeric())\n",
    "    # except AttributeError as e:\n",
    "    #     print(f\"Error using .str.isnumeric() on 'lat': {e}\")\n",
    "    # print(\"Explanation: .str accessor is for string-like operations. 'lat' is likely float64. \")\n",
    "    # print(\"If it were object type containing strings, you'd first convert to string or check types.\")\n",
    "# else:\n",
    "#     print(\"Circuits DataFrame not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recoding Numeric Variables 🔄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recoding numeric variables\n",
    "\n",
    "- Recoding is the process of changing the values of a variable\n",
    "- We can recode variables for various reasons\n",
    "  - To create new variables\n",
    "  - To standardise variables\n",
    "  - To simplify the analysis\n",
    "- Please remember to convert the variable to the correct type before recoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data type of the \"alt\" column\n",
    "if 'circuits' in locals() and not circuits.empty and 'alt' in circuits.columns:\n",
    "    print(circuits[\"alt\"].dtype)\n",
    "else:\n",
    "    print(\"Circuits DataFrame not loaded or 'alt' column missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `pd.to_numeric()` is used to convert a variable to a numeric type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_numeric() converts \n",
    "# a column to numeric\n",
    "# Before you use this option, \n",
    "# make sure to \"clean\" the variable\n",
    "# as we did before by checking what\n",
    "# the non-numeric values are\n",
    "if 'circuits' in locals() and not circuits.empty and 'alt' in circuits.columns:\n",
    "    circuits[\"alt_numeric\"] = pd.to_numeric(circuits[\"alt\"], errors='coerce') # errors='coerce' will turn unparseable strings into NaN\n",
    "    print(circuits[\"alt_numeric\"].mean())\n",
    "else:\n",
    "    print(\"Circuits DataFrame not loaded or 'alt' column missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'circuits' in locals() and not circuits.empty and 'alt_numeric' in circuits.columns:\n",
    "    print(circuits[\"alt_numeric\"].min())\n",
    "    print(circuits[\"alt_numeric\"].max())\n",
    "else:\n",
    "    print(\"Circuits DataFrame not loaded or 'alt_numeric' column missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recode variables based on an interval {#sec:recoding}\n",
    "\n",
    "- Imagine that we want to recode the `alt` variable into an interval\n",
    "\n",
    "$$x_{bin} = \\begin{cases} \"A\" &\\text{ if } x_1 < x \\le x_2 \\\\\n",
    "                             \"B\" &\\text{ if } x_2 < x \\le x_3 \\end{cases} $$\n",
    "\n",
    "- We can use the `pd.cut()` function to do this\n",
    "- The syntax is `df[\"new_variable\"] = pd.cut(df[\"variable\"], bins = [x1, x2, x3], labels = [\"A\", \"B\"])`\n",
    "- Where `bins` are the intervals and `labels` are the new values\n",
    "- More information about the function can be found [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode the \"alt\" variable into an interval\n",
    "if 'circuits' in locals() and not circuits.empty and 'alt_numeric' in circuits.columns:\n",
    "    bins_x = [0, 2500, 5000]\n",
    "    labels_x = [\"Between 0 and 2500\",\n",
    "                \"Between 2500 and 5000\"]\n",
    "\n",
    "    circuits[\"bins_alt\"] = pd.cut(circuits[\"alt_numeric\"],\n",
    "                                  bins = bins_x,\n",
    "                                  right = True,\n",
    "                                  labels = labels_x)\n",
    "    np.random.seed(2014)\n",
    "    display(circuits.sample(5))\n",
    "else:\n",
    "    print(\"Circuits DataFrame not loaded or 'alt_numeric' column missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And that's it for today! 🎉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thanks very much! 😊"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
